{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "FINAL END-TO-END CHURN PREDICTION & TIME-BASED EARLY WARNING SYSTEM\n",
        "- No leakage\n",
        "- Generalized\n",
        "- Realistic\n",
        "- Production-style evaluation\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# NEW: ADVANCED FEATURE ENGINEERING (TRENDS)\n",
        "# ======================================================\n",
        "def engineer_trend_features(df):\n",
        "    print(\"⚙း Engineering time-based trend features...\")\n",
        "    # Sort to ensure we compare the right months\n",
        "    df = df.sort_values(by=['Partner_ID', 'snapshot_date'])\n",
        "\n",
        "    # Columns we want to track changes for\n",
        "    cols_to_track = ['Login_Freq_Last_30d', 'Referral_Volume_30d', 'Commission_Payout_Last_30d']\n",
        "\n",
        "    for col in cols_to_track:\n",
        "        # Calculate % Change from previous row\n",
        "        # shift(1) gets the previous month's data for that partner\n",
        "        prev_col = df.groupby('Partner_ID')[col].shift(1)\n",
        "\n",
        "        # Create the Trend Column\n",
        "        # (Current - Previous) / Previous\n",
        "        df[f'{col}_Trend'] = (df[col] - prev_col) / (prev_col + 1e-6) # +1e-6 prevents divide by zero\n",
        "\n",
        "        # If it's the first month, Trend is 0\n",
        "        df[f'{col}_Trend'] = df[f'{col}_Trend'].fillna(0)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ======================================================\n",
        "# 1. CONFIGURATION (ONLY CHANGE THESE IF NEEDED)\n",
        "# ======================================================\n",
        "\n",
        "DATA_PATH = \"/content/AI_Partner_Churn_Dataset.csv\"\n",
        "TARGET_COLUMN = \"Churn_Label\"\n",
        "TIME_COLUMN = \"snapshot_date\"\n",
        "\n",
        "EARLY_WARNING_THRESHOLD = 0.65\n",
        "TRAIN_SPLIT_RATIO = 0.7\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ======================================================\n",
        "# 2. LOAD DATA\n",
        "# ======================================================\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Add time column if not present (CRITICAL: DO THIS BEFORE TRENDS)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "if TIME_COLUMN not in df.columns:\n",
        "    df[TIME_COLUMN] = pd.date_range(\n",
        "        start=\"2023-01-01\",\n",
        "        periods=len(df),\n",
        "        freq=\"D\"\n",
        "    )\n",
        "\n",
        "# APPLY THE NEW ENGINEERING\n",
        "df = engineer_trend_features(df)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "# ======================================================\n",
        "# 3. IDENTIFY ID & LEAKAGE COLUMNS\n",
        "# ======================================================\n",
        "\n",
        "LEAKAGE_COLS = [\n",
        "    TARGET_COLUMN,\n",
        "    \"Partner_ID\",\n",
        "    \"churn_probability\",\n",
        "    \"Churn_Probability\",\n",
        "    \"EarlyWarningScore\",\n",
        "    \"Top_Risk_Drivers\",\n",
        "    \"Recommended_Action\",\n",
        "    \"risk_tier\",\n",
        "    \"early_warning_flag\",\n",
        "    \"Manager_Priority\",\n",
        "    \"scenario_trigger\"\n",
        "]\n",
        "\n",
        "# ======================================================\n",
        "# 4. SORT BY TIME (CRITICAL FOR EARLY WARNING)\n",
        "# ======================================================\n",
        "\n",
        "df = df.sort_values(TIME_COLUMN).reset_index(drop=True)\n",
        "\n",
        "# ======================================================\n",
        "# 5. TIME-BASED TRAIN / TEST SPLIT\n",
        "# ======================================================\n",
        "\n",
        "split_index = int(len(df) * TRAIN_SPLIT_RATIO)\n",
        "\n",
        "train_df = df.iloc[:split_index]\n",
        "test_df  = df.iloc[split_index:]\n",
        "\n",
        "# Drop leakage and ID columns from training features\n",
        "cols_to_drop = [c for c in LEAKAGE_COLS + [TIME_COLUMN] if c in df.columns]\n",
        "\n",
        "X_train = train_df.drop(columns=cols_to_drop)\n",
        "y_train = train_df[TARGET_COLUMN]\n",
        "\n",
        "X_test  = test_df.drop(columns=cols_to_drop)\n",
        "y_test  = test_df[TARGET_COLUMN]\n",
        "\n",
        "# ======================================================\n",
        "# 6. AUTOMATIC FEATURE TYPE DETECTION\n",
        "# ======================================================\n",
        "\n",
        "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "print(\"Categorical columns:\", cat_cols)\n",
        "print(\"Numerical columns:\", num_cols)\n",
        "\n",
        "# ======================================================\n",
        "# 7. HANDLE MISSING VALUES\n",
        "# ======================================================\n",
        "\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])\n",
        "X_test[num_cols]  = num_imputer.transform(X_test[num_cols])\n",
        "\n",
        "X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])\n",
        "X_test[cat_cols]  = cat_imputer.transform(X_test[cat_cols])\n",
        "\n",
        "# ======================================================\n",
        "# 8. ENCODE CATEGORICAL FEATURES\n",
        "# ======================================================\n",
        "\n",
        "encoders = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
        "    X_test[col]  = le.transform(X_test[col].astype(str))\n",
        "    encoders[col] = le\n",
        "\n",
        "# ======================================================\n",
        "# 9. SCALE NUMERICAL FEATURES\n",
        "# ======================================================\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
        "X_test[num_cols]  = scaler.transform(X_test[num_cols])\n",
        "\n",
        "# ======================================================\n",
        "# 10. HANDLE CLASS IMBALANCE (TRAINING ONLY)\n",
        "# ======================================================\n",
        "\n",
        "print(\"\\nClass distribution before SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "smote = SMOTE(sampling_strategy=0.8, random_state=RANDOM_STATE)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(y_train_bal.value_counts())\n",
        "\n",
        "# ======================================================\n",
        "# 11. TRAIN XGBOOST MODEL\n",
        "# ======================================================\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=600,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.04,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    eval_metric=\"aucpr\",   # IMPORTANT\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# ======================================================\n",
        "# 12. TIME-BASED MODEL EVALUATION\n",
        "# ======================================================\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nTIME-BASED MODEL PERFORMANCE\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
        "\n",
        "# ======================================================\n",
        "# 13. EARLY WARNING DETECTION (HYBRID STRATEGY)\n",
        "# ======================================================\n",
        "\n",
        "test_df[\"churn_probability\"] = y_prob\n",
        "\n",
        "test_df[\"early_warning_flag\"] = (\n",
        "    test_df[\"churn_probability\"] >= EARLY_WARNING_THRESHOLD\n",
        ").astype(int)\n",
        "\n",
        "actual_churns = test_df[test_df[TARGET_COLUMN] == 1]\n",
        "early_detected = actual_churns[\n",
        "    actual_churns[\"early_warning_flag\"] == 1\n",
        "]\n",
        "\n",
        "early_detection_rate = len(early_detected) / len(actual_churns) if len(actual_churns) > 0 else 0\n",
        "\n",
        "print(\"\\nEARLY WARNING RESULTS\")\n",
        "print(\"Total future churns:\", len(actual_churns))\n",
        "print(\"Caught early:\", len(early_detected))\n",
        "print(\"Early detection rate:\", round(early_detection_rate, 2))\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 14. RISK TIERS\n",
        "# ======================================================\n",
        "\n",
        "def risk_tier(p):\n",
        "    if p >= 0.75:\n",
        "        return \"HIGH\"\n",
        "    elif p >= 0.45:\n",
        "        return \"MEDIUM\"\n",
        "    return \"LOW\"\n",
        "\n",
        "test_df[\"risk_tier\"] = test_df[\"churn_probability\"].apply(risk_tier)\n",
        "\n",
        "# ======================================================\n",
        "# 15. EXPLAINABILITY (SHAP)\n",
        "# ======================================================\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "feature_names = X_test.columns.tolist()\n",
        "\n",
        "def top_drivers_shap(shap_row, n=3):\n",
        "    idx = np.argsort(np.abs(shap_row))[-n:]\n",
        "    return \", \".join(feature_names[i] for i in idx)\n",
        "\n",
        "test_df[\"top_churn_drivers\"] = [\n",
        "    top_drivers_shap(shap_values[i])\n",
        "    for i in range(len(shap_values))\n",
        "]\n",
        "\n",
        "\n",
        "# Priority score = risk & value\n",
        "# Using test_df because it contains the 'churn_probability' predictions\n",
        "test_df[\"PriorityScore\"] = (\n",
        "    test_df[\"churn_probability\"] *\n",
        "    test_df[\"Commission_Payout_Last_30d\"]\n",
        ")\n",
        "\n",
        "test_df[\"Manager_Priority\"] = pd.qcut(\n",
        "    test_df[\"PriorityScore\"],\n",
        "    q=[0, 0.7, 0.9, 1.0],\n",
        "    labels=[\"Low\", \"Medium\", \"High\"]\n",
        ")\n",
        "\n",
        "print(\"Priority Distribution:\")\n",
        "print(test_df[\"Manager_Priority\"].value_counts())\n",
        "\n",
        "\n",
        "cohort_risk = (\n",
        "    test_df\n",
        "    .groupby([\"Region\", \"Partner_Tier\"])\n",
        "    .agg(\n",
        "        partners=(\"Region\", \"count\"),\n",
        "        avg_churn_prob=(\"churn_probability\", \"mean\"),\n",
        "        high_risk_pct=(\"risk_tier\", lambda x: (x == \"HIGH\").mean())\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "print(\"Cohort Risk Analysis:\")\n",
        "print(cohort_risk.sort_values(\"avg_churn_prob\", ascending=False).head())\n",
        "\n",
        "def recommend_action(drivers):\n",
        "    if \"risk_no_contact\" in drivers:\n",
        "        return \"Schedule immediate check-in call\"\n",
        "    if \"risk_negative_sentiment\" in drivers:\n",
        "        return \"Resolve support issue and follow up\"\n",
        "    if \"risk_referral_drop\" in drivers:\n",
        "        return \"Offer incentive or performance review\"\n",
        "    return \"Monitor closely\"\n",
        "\n",
        "# ======================================================\n",
        "# 16. SAVE FINAL OUTPUT\n",
        "# ======================================================\n",
        "\n",
        "test_df.to_csv(\"final_churn_time_based_predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\nSaved: final_churn_time_based_predictions.csv\")\n",
        "\n",
        "print(\"\\nSample HIGH-RISK EARLY WARNINGS:\")\n",
        "print(\n",
        "    test_df[test_df[\"risk_tier\" ] == \"HIGH\"]\n",
        "    [[\"churn_probability\", \"risk_tier\", \"early_warning_flag\", \"top_churn_drivers\"]]\n",
        "    .head()\n",
        ")\n"
      ],
      "metadata": {
        "id": "5fyLBaisihUl",
        "outputId": "692ac4fd-4b31-41dd-f0d2-92d406bf0f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙း Engineering time-based trend features...\n",
            "Dataset shape: (1000, 22)\n",
            "Categorical columns: ['Region', 'Partner_Tier']\n",
            "Numerical columns: ['Years_In_Network', 'Login_Freq_Last_30d', 'Login_Trend_Index', 'Dashboard_Usage_Minutes', 'Referral_Volume_30d', 'Referral_Growth_Rate', 'Support_Tickets_Open', 'Recent_Feedback_Sentiment', 'Days_Since_Last_Contact', 'Commission_Payout_Last_30d', 'Unresolved_Disputes_Count', 'Competitor_Mentioned', 'Technical_Integration_Issues', 'Login_Freq_Last_30d_Trend', 'Referral_Volume_30d_Trend', 'Commission_Payout_Last_30d_Trend']\n",
            "\n",
            "Class distribution before SMOTE:\n",
            "Churn_Label\n",
            "0    591\n",
            "1    109\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution after SMOTE:\n",
            "Churn_Label\n",
            "0    591\n",
            "1    472\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TIME-BASED MODEL PERFORMANCE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       254\n",
            "           1       0.60      0.52      0.56        46\n",
            "\n",
            "    accuracy                           0.87       300\n",
            "   macro avg       0.76      0.73      0.74       300\n",
            "weighted avg       0.87      0.87      0.87       300\n",
            "\n",
            "ROC-AUC: 0.8973\n",
            "\n",
            "EARLY WARNING RESULTS\n",
            "Total future churns: 46\n",
            "Caught early: 20\n",
            "Early detection rate: 0.43\n",
            "Priority Distribution:\n",
            "Manager_Priority\n",
            "Low       210\n",
            "Medium     60\n",
            "High       30\n",
            "Name: count, dtype: int64\n",
            "Cohort Risk Analysis:\n",
            "   Region Partner_Tier  partners  avg_churn_prob  high_risk_pct\n",
            "5    APAC       Silver        21        0.251364       0.190476\n",
            "10  LATAM         Gold         8        0.198872       0.000000\n",
            "3    APAC       Bronze        36        0.172115       0.083333\n",
            "0    AMER       Bronze        40        0.169970       0.100000\n",
            "6    EMEA       Bronze        57        0.159998       0.087719\n",
            "\n",
            "Saved: final_churn_time_based_predictions.csv\n",
            "\n",
            "Sample HIGH-RISK EARLY WARNINGS:\n",
            "     churn_probability risk_tier  early_warning_flag  \\\n",
            "721           0.995443      HIGH                   1   \n",
            "734           0.955266      HIGH                   1   \n",
            "748           0.849378      HIGH                   1   \n",
            "754           0.982124      HIGH                   1   \n",
            "756           0.920513      HIGH                   1   \n",
            "\n",
            "                                     top_churn_drivers  \n",
            "721  Days_Since_Last_Contact, Support_Tickets_Open,...  \n",
            "734  Recent_Feedback_Sentiment, Unresolved_Disputes...  \n",
            "748  Days_Since_Last_Contact, Support_Tickets_Open,...  \n",
            "754  Recent_Feedback_Sentiment, Days_Since_Last_Con...  \n",
            "756  Days_Since_Last_Contact, Support_Tickets_Open,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ----------------------------------------\n",
        "# LOAD LAST MODEL OUTPUT\n",
        "# ----------------------------------------\n",
        "\n",
        "df = pd.read_csv(\"final_churn_time_based_predictions.csv\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# SAFETY: NORMALIZE COLUMN NAMES\n",
        "# ----------------------------------------\n",
        "\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# ----------------------------------------\n",
        "# FIX MISSING COLUMNS / NAME MISMATCHES\n",
        "# ----------------------------------------\n",
        "\n",
        "# 1. Fallback for Partner_ID (it was dropped to prevent leakage earlier)\n",
        "if \"Partner_ID\" not in df.columns:\n",
        "    df[\"Partner_ID\"] = [f\"PTR-{i+1000}\" for i in range(len(df))]\n",
        "\n",
        "# 2. Map 'top_churn_drivers' (from SHAP) to 'Top_Risk_Drivers'\n",
        "if \"top_churn_drivers\" in df.columns:\n",
        "    df[\"Top_Risk_Drivers\"] = df[\"top_churn_drivers\"]\n",
        "\n",
        "# ----------------------------------------\n",
        "# ENSURE REQUIRED COLUMNS EXIST\n",
        "# ----------------------------------------\n",
        "\n",
        "required_cols = [\n",
        "    \"Partner_ID\",\n",
        "    \"Region\",\n",
        "    \"Partner_Tier\",\n",
        "    \"churn_probability\",\n",
        "    \"risk_tier\",\n",
        "    \"early_warning_flag\",\n",
        "    \"Manager_Priority\",\n",
        "    \"Top_Risk_Drivers\"\n",
        "]\n",
        "\n",
        "missing = [c for c in required_cols if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns: {missing}. Available: {df.columns.tolist()}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# RECOMMENDED ACTION LOGIC (ROBUST)\n",
        "# ----------------------------------------\n",
        "\n",
        "def recommend_action(drivers):\n",
        "    drivers = str(drivers).lower()\n",
        "    if \"no_contact\" in drivers or \"days_since_last_contact\" in drivers:\n",
        "        return \"Schedule immediate check-in call\"\n",
        "    if \"negative_sentiment\" in drivers or \"feedback\" in drivers:\n",
        "        return \"Resolve support issue and follow up\"\n",
        "    if \"referral\" in drivers:\n",
        "        return \"Offer incentive or performance review\"\n",
        "    if \"login\" in drivers:\n",
        "        return \"Re-engagement training or onboarding support\"\n",
        "    if \"support_tickets\" in drivers:\n",
        "        return \"Address technical hurdles or support backlog\"\n",
        "    return \"Monitor closely\"\n",
        "\n",
        "df[\"Recommended_Action\"] = df[\"Top_Risk_Drivers\"].apply(recommend_action)\n",
        "\n",
        "# ----------------------------------------\n",
        "# FINAL STREAMLIT DATAFRAME\n",
        "# ----------------------------------------\n",
        "\n",
        "final_df = df[\n",
        "    [\n",
        "        \"Partner_ID\",\n",
        "        \"Region\",\n",
        "        \"Partner_Tier\",\n",
        "        \"churn_probability\",\n",
        "        \"risk_tier\",\n",
        "        \"early_warning_flag\",\n",
        "        \"Manager_Priority\",\n",
        "        \"Top_Risk_Drivers\",\n",
        "        \"Recommended_Action\"\n",
        "    ]\n",
        "].sort_values(\"churn_probability\", ascending=False)\n",
        "\n",
        "# ----------------------------------------\n",
        "# SAVE CLEAN CSV\n",
        "# ----------------------------------------\n",
        "\n",
        "final_df.to_csv(\"streamlit_ready_churn_dashboard.csv\", index=False)\n",
        "\n",
        "print(\"✅ Clean Streamlit-ready CSV saved: streamlit_ready_churn_dashboard.csv\")\n",
        "print(f\"Processed {len(final_df)} partners.\")\n",
        "print(final_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wDa9yUpCD0N",
        "outputId": "58d16240-318a-4361-b78b-661fd1cb7ca9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean Streamlit-ready CSV saved: streamlit_ready_churn_dashboard.csv\n",
            "Processed 300 partners.\n",
            "       Partner_ID Region Partner_Tier  churn_probability risk_tier  \\\n",
            "21   PARTNER_0721   AMER       Silver           0.995443      HIGH   \n",
            "171  PARTNER_0871  LATAM       Silver           0.985463      HIGH   \n",
            "54   PARTNER_0754   APAC       Bronze           0.982124      HIGH   \n",
            "77   PARTNER_0777  LATAM       Bronze           0.969371      HIGH   \n",
            "144  PARTNER_0844   EMEA       Bronze           0.967789      HIGH   \n",
            "\n",
            "     early_warning_flag Manager_Priority  \\\n",
            "21                    1             High   \n",
            "171                   1             High   \n",
            "54                    1             High   \n",
            "77                    1             High   \n",
            "144                   1             High   \n",
            "\n",
            "                                      Top_Risk_Drivers  \\\n",
            "21   Days_Since_Last_Contact, Support_Tickets_Open,...   \n",
            "171  Competitor_Mentioned, Support_Tickets_Open, Re...   \n",
            "54   Recent_Feedback_Sentiment, Days_Since_Last_Con...   \n",
            "77   Region, Support_Tickets_Open, Unresolved_Dispu...   \n",
            "144  Recent_Feedback_Sentiment, Unresolved_Disputes...   \n",
            "\n",
            "                               Recommended_Action  \n",
            "21               Schedule immediate check-in call  \n",
            "171           Resolve support issue and follow up  \n",
            "54               Schedule immediate check-in call  \n",
            "77   Address technical hurdles or support backlog  \n",
            "144           Resolve support issue and follow up  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}